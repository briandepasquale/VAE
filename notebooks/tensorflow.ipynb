{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert VAE into julia with tensorflow\n",
    "## then convert to autograd.jl\n",
    "## then move over to python at some point?\n",
    "## do Bing model in TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TensorFlow, PyPlot, Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.367879\n",
       " 1.0     "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = TensorFlow.Session()\n",
    "\n",
    "x = TensorFlow.constant(Float64[1,2])\n",
    "y = TensorFlow.Variable(Float64[3,4])\n",
    "z = TensorFlow.placeholder(Float64)\n",
    "\n",
    "w = exp(x + z + -y)\n",
    "\n",
    "run(sess, TensorFlow.global_variables_initializer())\n",
    "res = run(sess, w, Dict(z=>Float64[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-27 17:36:06.688806: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.367879\n",
       " 1.0     "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = Session()\n",
    "\n",
    "x = constant(Float64[1,2])\n",
    "y = Variable(Float64[3,4])\n",
    "z = placeholder(Float64)\n",
    "\n",
    "w = exp(x + z + -y)\n",
    "\n",
    "run(sess, global_variables_initializer())\n",
    "res = run(sess, w, Dict(z=>Float64[1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mexp(x::AbstractArray{T}) where T <: Number is deprecated, use exp.(x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mexp\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m\n",
      " [4] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/IJulia/src/execute_request.jl:158\u001b[22m\u001b[22m\n",
      " [5] \u001b[1m(::Compat.#inner#14{Array{Any,1},IJulia.#execute_request,Tuple{ZMQ.Socket,IJulia.Msg}})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/Compat/src/Compat.jl:332\u001b[22m\u001b[22m\n",
      " [6] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[9], in expression starting on line 6\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mCheckpoint files saved in /tmp/tmpfK11Xp\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is 230.31.\n",
      "Current loss is 228.77.\n",
      "Current loss is 227.23.\n",
      "Current loss is 225.71.\n",
      "Current loss is 224.19.\n",
      "Current loss is 222.67.\n",
      "Current loss is 221.17.\n",
      "Current loss is 219.67.\n",
      "Current loss is 218.18.\n",
      "Current loss is 216.70.\n",
      "Current loss is 215.23.\n",
      "Current loss is 213.76.\n",
      "Current loss is 212.31.\n",
      "Current loss is 210.86.\n",
      "Current loss is 209.42.\n",
      "Current loss is 207.99.\n",
      "Current loss is 206.57.\n",
      "Current loss is 205.15.\n",
      "Current loss is 203.75.\n",
      "Current loss is 202.35.\n",
      "Current loss is 200.97.\n",
      "Current loss is 199.59.\n",
      "Current loss is 198.22.\n",
      "Current loss is 196.86.\n",
      "Current loss is 195.51.\n",
      "Current loss is 194.17.\n",
      "Current loss is 192.84.\n",
      "Current loss is 191.52.\n",
      "Current loss is 190.21.\n",
      "Current loss is 188.90.\n",
      "Current loss is 187.61.\n",
      "Current loss is 186.32.\n",
      "Current loss is 185.05.\n",
      "Current loss is 183.78.\n",
      "Current loss is 182.53.\n",
      "Current loss is 181.28.\n",
      "Current loss is 180.04.\n",
      "Current loss is 178.81.\n",
      "Current loss is 177.60.\n",
      "Current loss is 176.39.\n",
      "Current loss is 175.19.\n",
      "Current loss is 174.00.\n",
      "Current loss is 172.82.\n",
      "Current loss is 171.64.\n",
      "Current loss is 170.48.\n",
      "Current loss is 169.33.\n",
      "Current loss is 168.18.\n",
      "Current loss is 167.05.\n",
      "Current loss is 165.92.\n",
      "Current loss is 164.81.\n",
      "Current loss is 163.70.\n",
      "Current loss is 162.60.\n",
      "Current loss is 161.51.\n",
      "Current loss is 160.43.\n",
      "Current loss is 159.36.\n",
      "Current loss is 158.30.\n",
      "Current loss is 157.24.\n",
      "Current loss is 156.20.\n",
      "Current loss is 155.16.\n",
      "Current loss is 154.13.\n",
      "Current loss is 153.11.\n",
      "Current loss is 152.10.\n",
      "Current loss is 151.10.\n",
      "Current loss is 150.11.\n",
      "Current loss is 149.12.\n",
      "Current loss is 148.14.\n",
      "Current loss is 147.17.\n",
      "Current loss is 146.21.\n",
      "Current loss is 145.26.\n",
      "Current loss is 144.32.\n",
      "Current loss is 143.38.\n",
      "Current loss is 142.45.\n",
      "Current loss is 141.53.\n",
      "Current loss is 140.62.\n",
      "Current loss is 139.71.\n",
      "Current loss is 138.81.\n",
      "Current loss is 137.92.\n",
      "Current loss is 137.04.\n",
      "Current loss is 136.17.\n",
      "Current loss is 135.30.\n",
      "Current loss is 134.44.\n",
      "Current loss is 133.58.\n",
      "Current loss is 132.74.\n",
      "Current loss is 131.90.\n",
      "Current loss is 131.07.\n",
      "Current loss is 130.24.\n",
      "Current loss is 129.43.\n",
      "Current loss is 128.62.\n",
      "Current loss is 127.81.\n",
      "Current loss is 127.02.\n",
      "Current loss is 126.23.\n",
      "Current loss is 125.44.\n",
      "Current loss is 124.67.\n",
      "Current loss is 123.90.\n",
      "Current loss is 123.13.\n",
      "Current loss is 122.38.\n",
      "Current loss is 121.63.\n",
      "Current loss is 120.88.\n",
      "Current loss is 120.14.\n",
      "Current loss is 119.41.\n"
     ]
    }
   ],
   "source": [
    "# Generate some synthetic data\n",
    "x = randn(100, 50)\n",
    "w = randn(50, 10)\n",
    "y_prob = exp(x*w)\n",
    "y_prob ./= sum(y_prob,2)\n",
    "\n",
    "function draw(probs)\n",
    "    y = zeros(size(probs))\n",
    "    for i in 1:size(probs, 1)\n",
    "        idx = rand(Categorical(probs[i, :]))\n",
    "        y[i, idx] = 1\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "y = draw(y_prob)\n",
    "\n",
    "# Build the model\n",
    "sess = Session(Graph())\n",
    "X = placeholder(Float64)\n",
    "Y_obs = placeholder(Float64)\n",
    "\n",
    "variable_scope(\"logisitic_model\", initializer=Normal(0, .001)) do\n",
    "    global W = get_variable(\"weights\", [50, 10], Float64)\n",
    "    global B = get_variable(\"bias\", [10], Float64)\n",
    "end\n",
    "\n",
    "Y=nn.softmax(X*W + B)\n",
    "Loss = -reduce_sum(log(Y).*Y_obs)\n",
    "optimizer = train.AdamOptimizer()\n",
    "minimize_op = train.minimize(optimizer, Loss)\n",
    "saver = train.Saver()\n",
    "# Run training\n",
    "run(sess, global_variables_initializer())\n",
    "checkpoint_path = mktempdir()\n",
    "info(\"Checkpoint files saved in $checkpoint_path\")\n",
    "for epoch in 1:100\n",
    "    cur_loss, _ = run(sess, (Loss, minimize_op), Dict(X=>x, Y_obs=>y))\n",
    "    println(@sprintf(\"Current loss is %.2f.\", cur_loss))\n",
    "    train.save(saver, sess, joinpath(checkpoint_path, \"logistic\"), global_step=epoch)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader(1, [12186, 37123, 3620, 43683, 1666, 3016, 51650, 16050, 31528, 35133  â€¦  41997, 60, 29847, 37483, 59306, 17669, 26751, 23444, 38492, 44876])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(Pkg.dir(\"TensorFlow\", \"examples\", \"mnist_loader.jl\"))\n",
    "loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 16:13:11.766762: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Session(Ptr{Void} @0x00007f805361c730)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor placeholder_2:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = placeholder(Float32)\n",
    "y_ = placeholder(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = Variable(zeros(Float32, 784, 10))\n",
    "b = Variable(zeros(Float32, 10))\n",
    "\n",
    "run(sess, global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor reduce_2:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nn.softmax(x*W + b)\n",
    "Loss = reduce_mean(-reduce_sum(y_ .* log(y), axis=[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is 2.30.\n",
      "Current loss is 1.79.\n",
      "Current loss is 1.76.\n",
      "Current loss is 1.37.\n",
      "Current loss is 1.35.\n",
      "Current loss is 1.20.\n",
      "Current loss is 1.18.\n",
      "Current loss is 1.02.\n",
      "Current loss is 1.00.\n",
      "Current loss is 1.13.\n",
      "Current loss is 1.07.\n",
      "Current loss is 0.90.\n",
      "Current loss is 0.66.\n",
      "Current loss is 0.81.\n",
      "Current loss is 0.83.\n",
      "Current loss is 0.67.\n",
      "Current loss is 0.61.\n",
      "Current loss is 0.69.\n",
      "Current loss is 0.78.\n",
      "Current loss is 0.72.\n",
      "Current loss is 0.82.\n",
      "Current loss is 0.75.\n",
      "Current loss is 0.67.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.56.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.54.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.52.\n",
      "Current loss is 0.53.\n",
      "Current loss is 0.61.\n",
      "Current loss is 0.53.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.54.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.64.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.71.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.51.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.56.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.58.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.53.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.54.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.53.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.66.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.62.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.71.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.52.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.57.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.53.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.53.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.69.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.71.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.60.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.61.\n",
      "Current loss is 0.64.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.56.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.60.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.56.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.67.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.56.\n",
      "Current loss is 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is 0.28.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.71.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.64.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.54.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.51.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.53.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.56.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.57.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.53.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.52.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.70.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.57.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.51.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.53.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.52.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.57.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.56.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.37.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is 0.14.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.52.\n",
      "Current loss is 0.51.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.58.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.67.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.70.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.57.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.56.\n",
      "Current loss is 0.62.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.54.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.69.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.54.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.16.\n"
     ]
    }
   ],
   "source": [
    "optimizer = train.GradientDescentOptimizer(.00001)\n",
    "minimize_op = train.minimize(optimizer, Loss)\n",
    "\n",
    "for i in 1:1000\n",
    "    \n",
    "    batch = next_batch(loader, 100)\n",
    "    cur_loss, _ = run(sess, (Loss, minimize_op), Dict(x=>batch[1], y_=>batch[2]))\n",
    "    println(@sprintf(\"Current loss is %.2f.\", cur_loss))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Cast_46:1 shape=() dtype=Float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_prediction = cast(indmax(y, 2) .== indmax(y_, 2),Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[0.0 0.0 â€¦ 0.0 0.0; 0.0 0.0 â€¦ 0.0 0.0; â€¦ ; 0.0 0.0 â€¦ 0.0 0.0; 0.0 0.0 â€¦ 0.0 0.0], Float32[0.0 0.0 â€¦ 0.0 0.0; 0.0 0.0 â€¦ 0.0 0.0; â€¦ ; 0.0 0.0 â€¦ 0.0 0.0; 0.0 0.0 â€¦ 0.0 0.0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=reduce_mean(cast(correct_prediction, Float32))\n",
    "testx, testy = load_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9207"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(run(sess,indmax(y_,2),Dict(x=>testx, y_=>testy)) .== run(sess,indmax(y,2),Dict(x=>testx, y_=>testy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "println(run(sess, correct_prediction, Dict(x=>testx, y_=>testy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0f0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(sess, correct_prediction, Dict(x=>testx, y_=>testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xavier_init (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function xavier_init(fan_in, fan_out; constant=1) \n",
    "    \n",
    "    low = -constant*sqrt(6./(fan_in + fan_out)) \n",
    "    high = constant*sqrt(6./(fan_in + fan_out))\n",
    "    \n",
    "    #return random_uniform([fan_in, fan_out], low, high, dtype=Float32)\n",
    "    return map(Float32, rand(Uniform(low, high), fan_in, fan_out))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialize_weights (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialize_weights(n_hidden_recog_1, n_hidden_recog_2, \n",
    "                        n_hidden_gener_1,  n_hidden_gener_2, \n",
    "                        n_input, n_z)\n",
    "    \n",
    "    all_weights = Dict()\n",
    "    \n",
    "    all_weights[\"weights_recog\"] = Dict(\"h1\" => Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "        \"h2\" => Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "        \"out_mean\" => Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "        \"out_log_sigma\" => Variable(xavier_init(n_hidden_recog_2, n_z)))\n",
    "    \n",
    "    all_weights[\"biases_recog\"] = Dict(\"b1\" => Variable(zeros(Float32, n_hidden_recog_1)),\n",
    "        \"b2\" => Variable(zeros(Float32, n_hidden_recog_2)),\n",
    "        \"out_mean\" => Variable(zeros(Float32, n_z)),\n",
    "        \"out_log_sigma\" => Variable(zeros(Float32, n_z)))\n",
    "    \n",
    "    all_weights[\"weights_gener\"] = Dict(\"h1\" => Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "        \"h2\" => Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "        \"out_mean\" => Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "        \"out_log_sigma\" => Variable(xavier_init(n_hidden_gener_2, n_input)))\n",
    "    \n",
    "    all_weights[\"biases_gener\"] = Dict(\"b1\" => Variable(zeros(Float32, n_hidden_gener_1)),\n",
    "        \"b2\" => Variable(zeros(Float32, n_hidden_gener_2)),\n",
    "        \"out_mean\" => Variable(zeros(Float32, n_input)),\n",
    "        \"out_log_sigma\" => Variable(zeros(Float32, n_input)))\n",
    "    \n",
    "    return all_weights\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_network (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_network(network_architecture, x, batch_size)\n",
    "    \n",
    "    # Initialize autoencode network weights and biases\n",
    "    weights = initialize_weights(values(network_architecture)...)\n",
    "\n",
    "    # Use recognition network to determine mean and \n",
    "    # (log) variance of Gaussian distribution in latent\n",
    "    # space\n",
    "    z_Î¼, z_log_Ïƒ2 = recognition_network(x, weights[\"weights_recog\"], weights[\"biases_recog\"])\n",
    "\n",
    "    #Ïµ = map(Float32, rand(Normal(0, 1), batch_size, network_architecture[\"n_z\"]))\n",
    "    Ïµ = random_normal([batch_size, network_architecture[\"n_z\"]], mean=0, stddev=1, dtype=Float32)\n",
    "    # z = mu + sigma*epsilon\n",
    "    z = z_Î¼ + sqrt(exp(z_log_Ïƒ2)) .* Ïµ\n",
    "\n",
    "    # Use generator to determine mean of\n",
    "    # Bernoulli distribution of reconstructed input\n",
    "    x_hat_Î¼ = generator_network(z, weights[\"weights_gener\"], weights[\"biases_gener\"])\n",
    "    \n",
    "    return x_hat_Î¼, z_Î¼, z_log_Ïƒ2\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recognition_network (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function recognition_network(x, weights, biases; fct=nn.softplus)\n",
    "\n",
    "    layer_1 = fct(x * weights[\"h1\"] + biases[\"b1\"]) \n",
    "    layer_2 = fct(layer_1 * weights[\"h2\"] + biases[\"b2\"])\n",
    "    z_Î¼ = layer_2 * weights[\"out_mean\"] + biases[\"out_mean\"]\n",
    "    z_log_Ïƒ2 = layer_2 * weights[\"out_log_sigma\"] + biases[\"out_log_sigma\"]\n",
    "    \n",
    "    return z_Î¼, z_log_Ïƒ2\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator_network (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generator_network(z, weights, biases; fct=nn.softplus)\n",
    "\n",
    "    layer_1 = fct(z * weights[\"h1\"] + biases[\"b1\"])\n",
    "    layer_2 = fct(layer_1 * weights[\"h2\"] + biases[\"b2\"]) \n",
    "    x_hat_Î¼ = nn.sigmoid(layer_2 * weights[\"out_mean\"] + biases[\"out_mean\"])\n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_loss_optimizer (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_loss_optimizer(x,x_hat_Î¼,z_Î¼,z_log_Ïƒ2;learning_rate=0.001)\n",
    "    # The loss is composed of two terms:\n",
    "    # 1.) The reconstruction loss (the negative log probability\n",
    "    #     of the input under the reconstructed Bernoulli distribution \n",
    "    #     induced by the decoder in the data space).\n",
    "    #     This can be interpreted as the number of \"nats\" required\n",
    "    #     for reconstructing the input when the activation in latent\n",
    "    #     is given.\n",
    "    # Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "    reconstr_loss = -reduce_sum(x .* log(1e-10 + x_hat_Î¼) + (1-x) .* log(1e-10 + 1 - x_hat_Î¼), axis=[2])\n",
    "    # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "    ##    between the distribution in latent space induced by the encoder on \n",
    "    #     the data and some prior. This acts as a kind of regularizer.\n",
    "    #     This can be interpreted as the number of \"nats\" required\n",
    "    #     for transmitting the the latent space distribution given\n",
    "    #     the prior.\n",
    "    latent_loss = -0.5 * reduce_sum(1 + z_log_Ïƒ2 - z_Î¼^2 - exp(z_log_Ïƒ2), axis=[2])\n",
    "    \n",
    "    Loss = reduce_mean(reconstr_loss + latent_loss, axis=[1])   # average over batch\n",
    "    optimizer = train.minimize(train.AdamOptimizer(learning_rate), Loss) # Use ADAM optimizer\n",
    "        \n",
    "    return Loss, optimizer\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_test_set (generic function with 2 methods)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(Pkg.dir(\"TensorFlow\", \"examples\", \"mnist_loader.jl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainVAE (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function trainVAE(network_architecture; learning_rate=0.001,\n",
    "          batch_size=100, training_epochs=10, display_step=1, n_samples = 6e4)\n",
    "        \n",
    "    sess = Session(Graph())   \n",
    "    x = placeholder(Float32, shape=[nothing, network_architecture[\"n_input\"]])\n",
    "    x_hat_Î¼, z_Î¼, z_log_Ïƒ2 = create_network(network_architecture, x, batch_size)\n",
    "    Loss, optimizer = create_loss_optimizer(x, x_hat_Î¼, z_Î¼, z_log_Ïƒ2)\n",
    "\n",
    "    run(sess, global_variables_initializer())\n",
    "    loader = DataLoader()  \n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in 1:training_epochs\n",
    "\n",
    "        avg_cost = 0.\n",
    "        total_batch = Int(n_samples / batch_size)\n",
    "\n",
    "        # Loop over all batches\n",
    "        for i in 1:total_batch\n",
    "\n",
    "            batch_xs = next_batch(loader, batch_size)\n",
    "            batch_xs = broadcast(/,batch_xs[1],maximum(batch_xs[1],2));\n",
    "\n",
    "            # Fit training using batch data\n",
    "            cur_loss, = run(sess, (Loss, optimizer), Dict(x => batch_xs))\n",
    "            # Compute average loss\n",
    "            avg_cost += cur_loss / n_samples * batch_size\n",
    "\n",
    "        end\n",
    "\n",
    "        println(@sprintf(\"Epoch %.0f, current loss is %.9f.\", epoch, avg_cost))\n",
    "    \n",
    "    end\n",
    "    \n",
    "    return x_hat_Î¼, z_Î¼\n",
    "                \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 6 entries:\n",
       "  \"n_hidden_recog_1\" => 500\n",
       "  \"n_hidden_gener_1\" => 500\n",
       "  \"n_hidden_gener_2\" => 500\n",
       "  \"n_hidden_recog_2\" => 500\n",
       "  \"n_input\"          => 784\n",
       "  \"n_z\"              => 20"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_architecture = Dict(\"n_hidden_recog_1\" => 500, # 1st layer encoder neurons\n",
    "         \"n_hidden_recog_2\"=>500, # 2nd layer encoder neurons\n",
    "         \"n_hidden_gener_1\"=>500, # 1st layer decoder neurons\n",
    "         \"n_hidden_gener_2\"=>500, # 2nd layer decoder neurons\n",
    "         \"n_input\"=>784, # MNIST data input (img shape: 28*28)\n",
    "         \"n_z\"=>20)  # dimensionality of latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch, 1. Current loss is 173.294171638.\n",
      "Epoch, 2. Current loss is 127.410531584.\n",
      "Epoch, 3. Current loss is 117.108707075.\n",
      "Epoch, 4. Current loss is 112.730794705.\n",
      "Epoch, 5. Current loss is 110.082209444.\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mInterruptException:\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mInterruptException:\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mgetindex\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::UnitRange{Int64}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./strings/string.jl:245\u001b[22m\u001b[22m",
      " [2] \u001b[1mjoinpath\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./path.jl:213\u001b[22m\u001b[22m",
      " [3] \u001b[1mjoinpath\u001b[22m\u001b[22m at \u001b[1m./path.jl:205\u001b[22m\u001b[22m [inlined]",
      " [4] \u001b[1mget_code\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Status\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/src/core.jl:17\u001b[22m\u001b[22m",
      " [5] \u001b[1mcheck_status\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/src/core.jl:446\u001b[22m\u001b[22m [inlined]",
      " [6] \u001b[1mrun\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Session, ::Array{TensorFlow.Port,1}, ::Array{Any,1}, ::Array{TensorFlow.Port,1}, ::Array{Ptr{Void},1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/src/run.jl:109\u001b[22m\u001b[22m",
      " [7] \u001b[1mrun\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Session, ::Array{Tuple{TensorFlow.Tensor{Float64},TensorFlow.Tensor{Any}},1}, ::Dict{TensorFlow.Tensor{Float32},Array{Float32,2}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/src/run.jl:181\u001b[22m\u001b[22m",
      " [8] \u001b[1mrun\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Session, ::Tuple{TensorFlow.Tensor{Float64},TensorFlow.Tensor{Any}}, ::Dict{TensorFlow.Tensor{Float32},Array{Float32,2}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/src/run.jl:202\u001b[22m\u001b[22m",
      " [9] \u001b[1m#trainVAE#33\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Float64, ::Int64, ::Int64, ::Int64, ::Float64, ::Function, ::Dict{String,Int64}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[38]:25\u001b[22m\u001b[22m",
      " [10] \u001b[1m(::#kw##trainVAE)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#trainVAE, ::Dict{String,Int64}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "x_hat_Î¼, z_Î¼ = trainVAE(network_architecture, training_epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function transform(self, X):\n",
    "    \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "    # Note: This maps to mean of distribution, we could alternatively\n",
    "    # sample from Gaussian distribution\n",
    "    return self.sess.run(self.z_mean, feed_dict={self.x: X})\n",
    "    \n",
    "end\n",
    "\n",
    "function generate(self, z_mu=None):\n",
    "    \"\"\" Generate data by sampling from latent space.\n",
    "\n",
    "    If z_mu is not None, data for this point in latent space is\n",
    "    generated. Otherwise, z_mu is drawn from prior in latent \n",
    "    space.        \n",
    "    \"\"\"\n",
    "    if z_mu is None:\n",
    "        z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "    # Note: This maps to mean of distribution, we could alternatively\n",
    "    # sample from Gaussian distribution\n",
    "    return self.sess.run(self.x_reconstr_mean, \n",
    "                         feed_dict={self.z: z_mu})\n",
    "        \n",
    "end\n",
    "\n",
    "function reconstruct(self, X):\n",
    "    \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "    return self.sess.run(self.x_reconstr_mean, \n",
    "                         feed_dict={self.x: X})\n",
    "            \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch, 1.00. i, 1.00. Current loss is 1.005472716.\n",
      "Epoch, 1.00. i, 51.00. Current loss is 20.035243474.\n",
      "Epoch, 1.00. i, 101.00. Current loss is 36.890890043.\n",
      "Epoch, 1.00. i, 151.00. Current loss is 53.252647554.\n",
      "Epoch, 1.00. i, 201.00. Current loss is 68.872555356.\n",
      "Epoch, 1.00. i, 251.00. Current loss is 83.597622476.\n",
      "Epoch, 1.00. i, 301.00. Current loss is 97.584312587.\n",
      "Epoch, 1.00. i, 351.00. Current loss is 110.884676019.\n",
      "Epoch, 1.00. i, 401.00. Current loss is 123.687896829.\n",
      "Epoch, 1.00. i, 451.00. Current loss is 136.089046057.\n",
      "Epoch, 1.00. i, 501.00. Current loss is 148.221716736.\n",
      "Epoch, 1.00. i, 551.00. Current loss is 160.005223447.\n",
      "Epoch, 2.00. i, 1.00. Current loss is 0.238411428.\n",
      "Epoch, 2.00. i, 51.00. Current loss is 11.695106867.\n",
      "Epoch, 2.00. i, 101.00. Current loss is 22.906032935.\n",
      "Epoch, 2.00. i, 151.00. Current loss is 34.077120279.\n",
      "Epoch, 2.00. i, 201.00. Current loss is 45.071039479.\n",
      "Epoch, 2.00. i, 251.00. Current loss is 55.956950436.\n",
      "Epoch, 2.00. i, 301.00. Current loss is 66.588222241.\n",
      "Epoch, 2.00. i, 351.00. Current loss is 77.129376165.\n",
      "Epoch, 2.00. i, 401.00. Current loss is 87.561086910.\n",
      "Epoch, 2.00. i, 451.00. Current loss is 97.920560190.\n",
      "Epoch, 2.00. i, 501.00. Current loss is 108.219602269.\n",
      "Epoch, 2.00. i, 551.00. Current loss is 118.316209475.\n",
      "Epoch, 3.00. i, 1.00. Current loss is 0.207695500.\n",
      "Epoch, 3.00. i, 51.00. Current loss is 10.247749143.\n",
      "Epoch, 3.00. i, 101.00. Current loss is 20.180991699.\n",
      "Epoch, 3.00. i, 151.00. Current loss is 30.114869751.\n",
      "Epoch, 3.00. i, 201.00. Current loss is 39.942845363.\n",
      "Epoch, 3.00. i, 251.00. Current loss is 49.754873094.\n",
      "Epoch, 3.00. i, 301.00. Current loss is 59.420374944.\n",
      "Epoch, 3.00. i, 351.00. Current loss is 69.091610158.\n",
      "Epoch, 3.00. i, 401.00. Current loss is 78.727358755.\n",
      "Epoch, 3.00. i, 451.00. Current loss is 88.355216875.\n",
      "Epoch, 3.00. i, 501.00. Current loss is 97.976067568.\n",
      "Epoch, 3.00. i, 551.00. Current loss is 107.473291650.\n",
      "Epoch, 4.00. i, 1.00. Current loss is 0.198143888.\n",
      "Epoch, 4.00. i, 51.00. Current loss is 9.707834952.\n",
      "Epoch, 4.00. i, 101.00. Current loss is 19.152470103.\n",
      "Epoch, 4.00. i, 151.00. Current loss is 28.616297063.\n",
      "Epoch, 4.00. i, 201.00. Current loss is 38.038802256.\n",
      "Epoch, 4.00. i, 251.00. Current loss is 47.463626484.\n",
      "Epoch, 4.00. i, 301.00. Current loss is 56.772295121.\n",
      "Epoch, 4.00. i, 351.00. Current loss is 66.095000753.\n",
      "Epoch, 4.00. i, 401.00. Current loss is 75.430505588.\n",
      "Epoch, 4.00. i, 451.00. Current loss is 84.749261250.\n",
      "Epoch, 4.00. i, 501.00. Current loss is 94.078596877.\n",
      "Epoch, 4.00. i, 551.00. Current loss is 103.306858309.\n",
      "Epoch, 5.00. i, 1.00. Current loss is 0.192933817.\n",
      "Epoch, 5.00. i, 51.00. Current loss is 9.449551942.\n",
      "Epoch, 5.00. i, 101.00. Current loss is 18.646372467.\n",
      "Epoch, 5.00. i, 151.00. Current loss is 27.885067752.\n",
      "Epoch, 5.00. i, 201.00. Current loss is 37.088633121.\n",
      "Epoch, 5.00. i, 251.00. Current loss is 46.298963973.\n",
      "Epoch, 5.00. i, 301.00. Current loss is 55.405082721.\n",
      "Epoch, 5.00. i, 351.00. Current loss is 64.527445955.\n",
      "Epoch, 5.00. i, 401.00. Current loss is 73.656928119.\n",
      "Epoch, 5.00. i, 451.00. Current loss is 82.814782385.\n",
      "Epoch, 5.00. i, 501.00. Current loss is 91.982049908.\n",
      "Epoch, 5.00. i, 551.00. Current loss is 101.031792525.\n",
      "Epoch, 6.00. i, 1.00. Current loss is 0.189572390.\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mInterruptException:\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mInterruptException:\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1munsafe_read\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::IOStream, ::Ptr{UInt8}, ::UInt64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./iostream.jl:204\u001b[22m\u001b[22m",
      " [2] \u001b[1mread!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::IOStream, ::Array{UInt8,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./io.jl:387\u001b[22m\u001b[22m",
      " [3] \u001b[1mgetimage\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/MNIST/src/MNIST.jl:53\u001b[22m\u001b[22m",
      " [4] \u001b[1mtrainimage\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/MNIST/src/MNIST.jl:67\u001b[22m\u001b[22m [inlined]",
      " [5] \u001b[1mtrainfeatures\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/MNIST/src/MNIST.jl:82\u001b[22m\u001b[22m",
      " [6] \u001b[1mnext_batch\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::DataLoader, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/examples/mnist_loader.jl:14\u001b[22m\u001b[22m",
      " [7] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m./In[33]:10\u001b[22m\u001b[22m [inlined]",
      " [8] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m./<missing>:?\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "# Training cycle\n",
    "for epoch in 1:training_epochs\n",
    "    \n",
    "    avg_cost = 0.\n",
    "    total_batch = Int(n_samples / batch_size)\n",
    "    \n",
    "    # Loop over all batches\n",
    "    for i in 1:total_batch\n",
    "        \n",
    "        batch_xs = next_batch(loader, batch_size)\n",
    "        batch_xs = broadcast(/,batch_xs[1],maximum(batch_xs[1],2));\n",
    "\n",
    "        # Fit training using batch data\n",
    "        cur_loss, = run(sess, (Loss, optimizer), Dict(x => batch_xs))\n",
    "        # Compute average loss\n",
    "        avg_cost += cur_loss / n_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if Int(mod(i,display_step)) == 1\n",
    "            println(@sprintf(\"Epoch, %.2f. i, %.2f. Current loss is %.9f.\", epoch, i, avg_cost))\n",
    "        end\n",
    "        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader(1, [602, 9983, 38733, 18688, 27270, 13186, 28919, 15371, 32064, 41435  â€¦  4592, 2861, 41958, 36625, 34827, 14178, 42683, 1587, 54321, 4553])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate, batch_size, training_epochs, display_step, n_samples = 0.001,100, 10, 50, 6e4\n",
    "    \n",
    "sess = Session(Graph())\n",
    "    \n",
    "x = placeholder(Float32, shape=[nothing, network_architecture[\"n_input\"]])\n",
    "\n",
    "x_hat_Î¼, z_Î¼, z_log_Ïƒ2 = create_network(network_architecture, x, batch_size)\n",
    "Loss, optimizer = create_loss_optimizer(x, x_hat_Î¼, z_Î¼, z_log_Ïƒ2)\n",
    "\n",
    "run(sess, global_variables_initializer())\n",
    "\n",
    "loader = DataLoader()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close(sess)\n",
    "\n",
    "#function test(network_architecture; learning_rate=0.001,\n",
    "#          batch_size=100, training_epochs=10, display_step=5, n_samples = 6e4)\n",
    "    \n",
    "loader = DataLoader()    \n",
    "sess = Session(Graph())\n",
    "\n",
    "x = placeholder(Float32, shape=[nothing, network_architecture[\"n_input\"]])\n",
    "\n",
    "x_hat_Î¼, z_Î¼, z_log_Ïƒ2 = create_network(network_architecture, x)\n",
    "Loss, optimizer = create_loss_optimizer(x, x_hat_Î¼, z_Î¼, z_log_Ïƒ2)\n",
    "\n",
    "run(sess, global_variables_initializer())\n",
    "\n",
    "batch_xs = next_batch(loader, 100)\n",
    "\n",
    "run(sess, Loss, Dict(x => batch_xs[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate, batch_size, training_epochs, display_step, n_samples = 0.001,100, 10, 1, 6e4\n",
    "\n",
    "sess = Session(Graph())\n",
    "    \n",
    "x = placeholder(Float32, shape=[nothing, network_architecture[\"n_input\"]])\n",
    "\n",
    "x_hat_Î¼, z_Î¼, z_log_Ïƒ2, z, = create_network(network_architecture, x, batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()    \n",
    "batch_xs = next_batch(loader, batch_size);\n",
    "batch_xs = broadcast(/,batch_xs[1],maximum(batch_xs[1],2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " 546.549   \n",
       "    nothing"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_loss, = run(sess, (Loss, optimizer), Dict(x => batch_xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Tensor reduce_3:1 shape=() dtype=Float64>, <Tensor Group:1 shape=unknown dtype=Any>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loss, optimizer = create_loss_optimizer(x, x_hat_Î¼, z_Î¼, z_log_Ïƒ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(sess, global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1Ã—2 Array{Float32,2}:\n",
       " 2.2927  0.660526"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(sess, z_Î¼,Dict(x => batch_xs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1Ã—10 Array{Float32,2}:\n",
       " 8.87964  0.0  129.173  0.0  282.515  0.280485  â€¦  9.87321  1.45998  80.3929"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(sess,layer_1,Dict(x => batch_xs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float32,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(sess, weights[\"biases_recog\"][\"b2\"] , Dict(x => batch_xs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{PyCall.PyObject,1}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x7f200c792c10>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(vec(batch_xs[1])/maximum(batch_xs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.collections.QuadMesh object at 0x7f200c711b10>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcolormesh(reshape(batch_xs[1],28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{PyCall.PyObject,1}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x7f20cc726bd0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(sort(vec(run(sess, weights[\"weights_recog\"][\"out_log_sigma\"],Dict(x => batch_xs[1])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0f0, 0.0f0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah = map(x->x[1],batch_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_architecture = Dict(\"n_hidden_recog_1\" => 10, # 1st layer encoder neurons\n",
    "         \"n_hidden_recog_2\"=>10, # 2nd layer encoder neurons\n",
    "         \"n_hidden_gener_1\"=>10, # 1st layer decoder neurons\n",
    "         \"n_hidden_gener_2\"=>10, # 2nd layer decoder neurons\n",
    "         \"n_input\"=>784, # MNIST data input (img shape: 28*28)\n",
    "         \"n_z\"=>2)  # dimensionality of latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## various experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Polynomial{R}\n",
    "    coeffs::Vector{R}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (p::Polynomial)(x)\n",
    "   v = p.coeffs[end]\n",
    "   for i = (length(p.coeffs)-1):-1:1\n",
    "       v = v*x + p.coeffs[i]\n",
    "   end\n",
    "   return v\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polynomial{Int64}([1, 10, 100])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Polynomial([1,10,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct VAE2\n",
    "    x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(1.0, 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(1.,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE2(<Tensor placeholder_15:1 shape=unknown dtype=Float32>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae2 = VAE2(placeholder(Float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor placeholder_15:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_pool_2x2 (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(Pkg.dir(\"TensorFlow\", \"examples\", \"mnist_loader.jl\"))\n",
    "\n",
    "close(session)\n",
    "\n",
    "loader = DataLoader()\n",
    "\n",
    "session = Session(Graph())\n",
    "\n",
    "function weight_variable(shape)\n",
    "    initial = map(Float32, rand(Normal(0, .001), shape...))\n",
    "    return Variable(initial)\n",
    "end\n",
    "\n",
    "function bias_variable(shape)\n",
    "    initial = fill(Float32(.1), shape...)\n",
    "    return Variable(initial)\n",
    "end\n",
    "\n",
    "function conv2d(x, W)\n",
    "    nn.conv2d(x, W, [1, 1, 1, 1], \"SAME\")\n",
    "end\n",
    "\n",
    "function max_pool_2x2(x)\n",
    "    nn.max_pool(x, [1, 2, 2, 1], [1, 2, 2, 1], \"SAME\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFlow.Variables.Variable{Float32}(<Tensor node_43:1 shape=(5, 5, 1, 32) dtype=Float32>, <Tensor node_43/Assign:1 shape=unknown dtype=Float32>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = [5, 5, 1, 32]\n",
    "initial = map(Float32, rand(Normal(0, .001), shape...))\n",
    "Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 1, 32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = placeholder(Float32)\n",
    "y_ = placeholder(Float32)\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "h_conv1 = nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = nn.relu(h_pool2_flat * W_fc1 + b_fc1)\n",
    "\n",
    "keep_prob = placeholder(Float32)\n",
    "h_fc1_drop = nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = nn.softmax(h_fc1_drop * W_fc2 + b_fc2)\n",
    "\n",
    "cross_entropy = reduce_mean(-reduce_sum(y_.*log(y_conv), axis=[2]))\n",
    "\n",
    "train_step = train.minimize(train.AdamOptimizer(1e-4), cross_entropy)\n",
    "\n",
    "correct_prediction = indmax(y_conv, 2) .== indmax(y_, 2)\n",
    "\n",
    "#accuracy = reduce_mean(cast(correct_prediction, Float32))\n",
    "accuracy = (cast(correct_prediction, Float32))\n",
    "\n",
    "#optimizer = train.GradientDescentOptimizer(.00001)\n",
    "#minimize_op = train.minimize(optimizer, Loss)\n",
    "\n",
    "run(session, global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFlow.Variables.Variable{Float32}(<Tensor node_19:1 shape=(5, 5, 32, 64) dtype=Float32>, <Tensor node_19/Assign:1 shape=unknown dtype=Float32>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is 2.30.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.31.\n",
      "Current loss is 2.31.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.31.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.31.\n",
      "Current loss is 2.29.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.31.\n",
      "Current loss is 2.31.\n",
      "Current loss is 2.29.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.29.\n",
      "Current loss is 2.29.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.31.\n",
      "Current loss is 2.29.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.29.\n",
      "Current loss is 2.27.\n",
      "Current loss is 2.30.\n",
      "Current loss is 2.28.\n",
      "Current loss is 2.29.\n",
      "Current loss is 2.23.\n",
      "Current loss is 2.27.\n",
      "Current loss is 2.27.\n",
      "Current loss is 2.17.\n",
      "Current loss is 2.25.\n",
      "Current loss is 2.21.\n",
      "Current loss is 2.31.\n",
      "Current loss is 2.15.\n",
      "Current loss is 2.24.\n",
      "Current loss is 2.18.\n",
      "Current loss is 2.10.\n",
      "Current loss is 2.22.\n",
      "Current loss is 1.96.\n",
      "Current loss is 2.06.\n",
      "Current loss is 2.08.\n",
      "Current loss is 2.01.\n",
      "Current loss is 1.90.\n",
      "Current loss is 1.77.\n",
      "Current loss is 1.76.\n",
      "Current loss is 1.62.\n",
      "Current loss is 1.44.\n",
      "Current loss is 1.65.\n",
      "Current loss is 1.52.\n",
      "Current loss is 1.53.\n",
      "Current loss is 1.38.\n",
      "Current loss is 1.16.\n",
      "Current loss is 1.19.\n",
      "Current loss is 1.31.\n",
      "Current loss is 1.27.\n",
      "Current loss is 1.05.\n",
      "Current loss is 1.33.\n",
      "Current loss is 1.04.\n",
      "Current loss is 1.22.\n",
      "Current loss is 1.37.\n",
      "Current loss is 1.07.\n",
      "Current loss is 1.08.\n",
      "Current loss is 0.96.\n",
      "Current loss is 0.80.\n",
      "Current loss is 0.87.\n",
      "Current loss is 0.97.\n",
      "Current loss is 0.72.\n",
      "Current loss is 0.93.\n",
      "Current loss is 0.70.\n",
      "Current loss is 0.81.\n",
      "Current loss is 0.89.\n",
      "Current loss is 0.89.\n",
      "Current loss is 0.80.\n",
      "Current loss is 0.78.\n",
      "Current loss is 0.64.\n",
      "Current loss is 0.79.\n",
      "Current loss is 0.62.\n",
      "Current loss is 0.67.\n",
      "Current loss is 0.79.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.62.\n",
      "Current loss is 0.57.\n",
      "Current loss is 0.61.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.60.\n",
      "Current loss is 0.75.\n",
      "Current loss is 0.74.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.54.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.71.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.67.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.76.\n",
      "Current loss is 0.52.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.73.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.51.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.67.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.43.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.44.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.49.\n",
      "Current loss is 0.52.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.50.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.59.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.52.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.42.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.56.\n",
      "Current loss is 0.48.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.51.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.52.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.38.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.55.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.37.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.45.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is 0.22.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.47.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.41.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.36.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.34.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.30.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.40.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.33.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.35.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.28.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.32.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.46.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.31.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.17.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is 0.14.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.26.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.27.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.20.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.16.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.25.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.23.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.19.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.15.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.21.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.22.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.11.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.05.\n",
      "Current loss is 0.29.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.07.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.09.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.18.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.04.\n",
      "Current loss is 0.02.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.01.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.06.\n",
      "Current loss is 0.12.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.10.\n",
      "Current loss is 0.17.\n",
      "Current loss is 0.13.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.14.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.03.\n",
      "Current loss is 0.24.\n",
      "Current loss is 0.08.\n",
      "Current loss is 0.39.\n",
      "Current loss is 0.06.\n"
     ]
    }
   ],
   "source": [
    "for i in 1:1000\n",
    "    batch = next_batch(loader, 50)\n",
    "    #if i%100 == 1\n",
    "    #    train_accuracy = run(session, accuracy, Dict(x=>batch[1], y_=>batch[2], keep_prob=>1.0))\n",
    "    #    info(\"step $i, training accuracy $train_accuracy\")\n",
    "    #end\n",
    "    cur_loss, _ = run(session, (cross_entropy, train_step), Dict(x=>batch[1], y_=>batch[2], keep_prob=>.5))\n",
    "    #run(session, train_step, Dict(x=>batch[1], y_=>batch[2], keep_prob=>.5))\n",
    "    println(@sprintf(\"Current loss is %.2f.\", cur_loss))\n",
    "end\n",
    "\n",
    "#testx, testy = load_test_set()\n",
    "#test_accuracy = run(session, accuracy, Dict(x=>testx, y_=>testy, keep_prob=>1.0))\n",
    "#info(\"test accuracy $test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 19:48:51.154371: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "TensorBoard 1.8.0 at http://scotty.pni.Princeton.EDU:6008 (Press CTRL+C to quit)\n",
      "2018-11-25 19:48:53.818721: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "TensorBoard 1.8.0 at http://scotty.pni.Princeton.EDU:6009 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START /usr/bin/firefox \"http://localhost:6009/#graphs\"\n",
      "Running without a11y support!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to open connection to \"session\" message bus: Using X11 for dbus-daemon autolaunch was disabled at compile time, set your DBUS_SESSION_BUS_ADDRESS instead\n",
      "/usr/lib64/firefox/firefox: symbol lookup error: /lib64/libgtk-3.so.0: undefined symbol: g_log_structured_standard\n",
      "xdg-open: no method available for opening 'http://localhost:6009/#graphs'\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mfailed process: Process(`xdg-open 'http://localhost:6009/#graphs'`, ProcessExited(3)) [3]\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mfailed process: Process(`xdg-open 'http://localhost:6009/#graphs'`, ProcessExited(3)) [3]\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mpipeline_error\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Base.Process\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./process.jl:682\u001b[22m\u001b[22m",
      " [2] \u001b[1mrun\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Cmd\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./process.jl:651\u001b[22m\u001b[22m",
      " [3] \u001b[1mopen_url\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/src/show.jl:196\u001b[22m\u001b[22m",
      " [4] \u001b[1mvisualize\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.summary.FileWriter\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/src/show.jl:218\u001b[22m\u001b[22m",
      " [5] \u001b[1mvisualize\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Graph\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/src/show.jl:212\u001b[22m\u001b[22m",
      " [6] \u001b[1mvisualize\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/mnt/bucket/people/briandd/.conda/envs/julia/share/julia/site/v0.6/TensorFlow/src/core.jl:291\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9796"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(run(session,indmax(y_,2),Dict(x=>testx, y_=>testy, keep_prob=>1.0)) .== \n",
    "    run(session,indmax(y_conv,2),Dict(x=>testx, y_=>testy, keep_prob=>1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mtest accuracy 0.0\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "testx, testy = load_test_set()\n",
    "test_accuracy = run(session, accuracy, Dict(x=>testx, y_=>testy, keep_prob=>1.0))\n",
    "info(\"test accuracy $test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct VAE4\n",
    "\n",
    "    network_architecture::Dict\n",
    "    transfer_fct\n",
    "    learning_rate::Float64\n",
    "    batch_size::Int\n",
    "    x\n",
    "    z_mean\n",
    "    z_log_sigma_sq\n",
    "    z\n",
    "    x_reconstr_mean\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor placeholder_3:1 shape=(?, 784) dtype=Float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae2 = VAE4(Dict(),nn.softplus,0.001,100,[],[],[],[],[])\n",
    "x = placeholder(Float32, shape=[nothing, network_architecture[\"n_input\"]])\n",
    "#vae2.x = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    #def __init__(self, network_architecture, transfer_fct=tf.nn.softplus, \n",
    "    #             learning_rate=0.001, batch_size=100):\n",
    "\n",
    "    #sess\n",
    "\n",
    "    #function VariationalAutoencoder(network_architecture)\n",
    "    #    network_weights = initialize_weights(network_architecture)\n",
    "    #end\n",
    "\n",
    "    # tf Graph input\n",
    "    #x = placeholder(Float32, [None, network_architecture[\"n_input\"]])\n",
    "\n",
    "    # Create autoencoder network\n",
    "    #self._create_network()\n",
    "    # Define loss function based variational upper-bound and \n",
    "    # corresponding optimizer\n",
    "    #self._create_loss_optimizer()\n",
    "\n",
    "    # Initializing the tensor flow variables\n",
    "    #init = global_variables_initializer()\n",
    "\n",
    "    # Launch the session\n",
    "    #sess = InteractiveSession()\n",
    "    #sess(run,init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
